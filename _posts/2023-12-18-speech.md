---
# date: 2010-09-10 12:26:40
layout: post
title: Speech Demo
subtitle: Lorem ipsum dolor sit amet, consectetur adipisicing elit.
description: This video demo combines visuals created in Unreal engine with a Dolby Atmos mix of an original composition by Jacob Cooper.

image: https://res.cloudinary.com/dhwvtuay6/image/upload/c_scale,w_800/v1705507835/IMG_5206_keht27.jpg
optimized_image: https://res.cloudinary.com/dhwvtuay6/image/upload/c_scale,w_360/v1705507835/IMG_5206_keht27.jpg
category: demo
tags:
  - ambisonics
  - motion capture
author: Jacob Cooper
---

This series of webpages provides an account of the audiovisual workflows used to produce three different immersive pieces as part of the [Developing a Database of Immersive Audiovisual Materials](https://audiolab.york.ac.uk/developing-a-database-of-immersive-audiovisual-materials/) project:

- Maida Vale live performance demo
- Macbeth demo
- Spatialised speech demo

Each of these demos showcases a different context for immersive audiovisual media. The first looks at live music performance; the second, more traditional film and television content; and the third, a more abstract / artistic use.

All were created through combining spatial audio workflows and motion-capture technologies in slightly different ways that will be explored through this series of webpages.

This video demo combines visuals created in Unreal engine with a 7OA mix of a performance of an [original script](https://docs.google.com/document/d/1hCobMf0VD5jZucFdqOWcBLIS-1ManEzMprjPOTJdQZA/edit) about the evolution of sound and spatial audio technology.

[https://youtu.be/HmCGLzvrTQc](https://youtu.be/HmCGLzvrTQc)

# Audio Workflow

## Recording

Recorded using an AKG C414, shock mount and pop filter in an anechoic chamber.

![Recording setup used for speech demo.](https://res.cloudinary.com/dhwvtuay6/image/upload/c_scale,w_800/v1705507835/IMG_5206_keht27.jpg)

Recording setup used for speech demo.

## Sound Effects

Sound effects sourced from SoundSnap.

## Mixing

Mixed using a 7OA workflow in Reaper. Key processing applied is as follows:

### Pre-processing: iZotope RX9

Spectral de-noise used to remove noise.

Mouth de-click used to remove mouth noises

### Encoding: 7th Order Encoding

Plug-ins used: IEM MultiEncoder and AmbiX o7 Encoder

### Convolution: X-MCFX Convolver

Facilitates convolution with real-world Spatial Room Impulse Responses (SRIRs)

### Reverbs: IEM FdnReverb

Three reverb sends used with varying reverb times: 0.3 s, 2.1 s and 4.5 s

## Deliverable Formats

The audio was provided in the following formats:

- Binaural
- 7.1.4
- 7th Order Ambisonics
- EBU ADM

The BBCâ€™s EAR Production Suite was used to create an EBU ADM file. The EBU ADM file contained 2 HOA files: one for the reverb and the other for the spatial sound effects used; the rest of the sounds were (mono) objects. The automation data was copied from the Ambisonic encoders to the EAR object plug-ins. The stems were also provided separately.

The audio was converted to binaural using decoding filters developed by Tomasz Rudzki. The audio was converted to 7.1.4 using the SPARTA decoder (no audio was rendered to the LFE channel); this used the Dolby Atmos routing (SSL and SSR were sent to outputs 5 & 6).

# Visual Workflow

The visuals were constructed using the following:

- Face-tracking captured using LiveLink Face For Unreal Engine
- Project assembly using Unreal Engine 5

## Face-Tracking

Face-tracking was recorded using the LiveLink Face for Unreal application for Apple devices (with True Depth camera).

## Project Assembly

The tracking data was imported into Unreal and used to animate a metahuman. The locations of the metahuman on screen provide an indicator of the position of the voice.

# Credits

### Recording, Production & Mixing

Jacob Cooper

### Motion-Capture Performance

Stephanie Ornithari Roberts

### Visuals

Joe Rees-Jones